name: Run Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight UTC

permissions:
  contents: 'read'
  id-token: 'write'

jobs:
  scrape:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/813050693418/locations/global/workloadIdentityPools/github-actions-scrape-centris/providers/github'
          service_account: 'scrape-centris@dfrancoeur.iam.gserviceaccount.com'
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: '.python-version'
          
      - name: Install Poetry
        run: pip install poetry
          
      - name: Install dependencies
        run: poetry install --no-root --no-interaction

      - name: Set required environment variables
        run: |
          CURRENT_DATETIME=$(date +"%Y%m%d_%H%M%S")
          echo "CURRENT_DATETIME=${CURRENT_DATETIME}" >> "$GITHUB_ENV"

          OUTPUT_FILE="listings_${CURRENT_DATETIME}.json"
          echo "OUTPUT_FILE=${OUTPUT_FILE}" >> "$GITHUB_ENV"

      - name: Run scraper
        run: .github/scripts/run.sh

      - id: 'upload-file'
        uses: 'google-github-actions/upload-cloud-storage@v2'
        with:
          path: ${{ env.OUTPUT_FILE }}
          destination: ${{ secrets.GCS_BUCKET_SCRAPE_CENTRIS }}
